{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "DATASET_PATH = \"dataset\"\n",
    "CLASSES = [\"correct_mask\", \"incorrect_mask\"]\n",
    "LOG_FILE = \"results_log.txt\"\n",
    "MODEL_FILE = \"hog_svm_model_optimized.pkl\"  # output ismi\n",
    "PCA_FILE = \"pca_model.pkl\"\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOG_PARAMS = {\n",
    "    'orientations': 12,\n",
    "    'pixels_per_cell': (6, 6),\n",
    "    'cells_per_block': (3, 3),\n",
    "    'block_norm': 'L2-Hys',\n",
    "    'transform_sqrt': True,\n",
    "    'feature_vector': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e893b43",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "SVM_PARAMS = {\n",
    "    'C': 1.0,\n",
    "    'max_iter': 2000,\n",
    "    'random_state': 42,\n",
    "    'dual': False,\n",
    "    'tol': 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24575b3a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_hog_features(image, hog_params=HOG_PARAMS):\n",
    "    features = hog(image, **hog_params)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec23b0c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image, img_size=IMG_SIZE):\n",
    "    \"\"\"Test koduyla uyumlu ön işleme\"\"\"\n",
    "    # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    image = clahe.apply(image)\n",
    "    \n",
    "    # Bilateral filter - edge preserving\n",
    "    image = cv2.bilateralFilter(image, 5, 50, 50)\n",
    "    \n",
    "    image = cv2.resize(image, (img_size, img_size), interpolation=cv2.INTER_LANCZOS4)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Genişletme\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc0e7b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data_efficiently():\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label, class_name in enumerate(CLASSES):\n",
    "        folder_path = os.path.join(DATASET_PATH, class_name)\n",
    "        files_list = [os.path.join(root, file) for root, _, files in os.walk(folder_path) for file in files if file.lower().endswith((\".jpg\", \".png\", \".jpeg\", \".bmp\"))]\n",
    "        for img_path in tqdm(files_list, desc=f\"Processing {class_name}\"):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img_processed = preprocess_image(img)\n",
    "            hog_feat = extract_hog_features(img_processed)\n",
    "            all_features.append(hog_feat)\n",
    "            all_labels.append(label)\n",
    "    return np.array(all_features), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760a418",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def optimize_features(X, n_components=0.95):\n",
    "    print(f\"PCA uygulanıyor: {X.shape} -> \", end=\"\")\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    print(f\"{X_reduced.shape}\")\n",
    "    \n",
    "    # Model Kaydet\n",
    "    joblib.dump(pca, PCA_FILE)\n",
    "    print(f\"PCA modeli kaydedildi: {PCA_FILE}\")\n",
    "    \n",
    "    return X_reduced, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0b77a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', LinearSVC(random_state=42, max_iter=3000))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'svm__C': [0.1, 1.0, 10.0],\n",
    "        'svm__loss': ['hinge', 'squared_hinge'],\n",
    "        'svm__dual': [False],\n",
    "        'svm__tol': [1e-4, 1e-3]\n",
    "    }\n",
    "\n",
    "    print(\"Hiperparametre optimizasyonu başlıyor...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"En iyi parametreler: {grid_search.best_params_}\")\n",
    "    print(f\"En iyi skor: {grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e5b06",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate():\n",
    "    print(\"Veri yükleniyor...\")\n",
    "    X, y = load_data_efficiently()\n",
    "    print(f\"Toplam örnek sayısı: {X.shape[0]}\")\n",
    "    print(f\"Özellik boyutu: {X.shape[1]}\")\n",
    "    \n",
    "    pca = None\n",
    "    if X.shape[1] > 1000:\n",
    "        X, pca = optimize_features(X, n_components=0.95)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"Eğitim seti: {X_train.shape[0]}, Test seti: {X_test.shape[0]}\")\n",
    "\n",
    "    # Basit model\n",
    "    print(\"\\nBasit model eğitiliyor...\")\n",
    "    simple_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', LinearSVC(**SVM_PARAMS))\n",
    "    ])\n",
    "    simple_model.fit(X_train, y_train)\n",
    "    simple_pred = simple_model.predict(X_test)\n",
    "    simple_accuracy = accuracy_score(y_test, simple_pred)\n",
    "    print(f\"Basit model doğruluğu: {simple_accuracy:.4f}\")\n",
    "\n",
    "    # Optimize model\n",
    "    print(\"\\nOptimize model eğitiliyor...\")\n",
    "    optimized_model = hyperparameter_optimization(X_train, y_train)\n",
    "    optimized_pred = optimized_model.predict(X_test)\n",
    "    optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "    print(f\"Optimize model doğruluğu: {optimized_accuracy:.4f}\")\n",
    "\n",
    "    # Cross validation\n",
    "    cv_scores = cross_val_score(optimized_model, X_train, y_train, cv=3)\n",
    "    print(f\"Cross validation skorları: {cv_scores}\")\n",
    "    print(f\"Ortalama CV skoru: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "    # Modeli kaydet\n",
    "    joblib.dump(optimized_model, MODEL_FILE)\n",
    "    print(f\"Model kaydedildi: {MODEL_FILE}\")\n",
    "    \n",
    "    # Detaylı rapor\n",
    "    print(\"\\nDetaylı sınıflandırma raporu:\")\n",
    "    print(classification_report(y_test, optimized_pred, target_names=CLASSES))\n",
    "    \n",
    "    return optimized_model, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e2a79",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict_single_image(model_path, image_path, pca_path=None):\n",
    "    model = joblib.load(model_path)\n",
    "    pca = joblib.load(pca_path) if pca_path and os.path.exists(pca_path) else None\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Görüntü yüklenemedi: {image_path}\")\n",
    "        return None\n",
    "        \n",
    "    img_processed = preprocess_image(img)\n",
    "    hog_feat = extract_hog_features(img_processed)\n",
    "    features = hog_feat.reshape(1, -1)\n",
    "    \n",
    "    if pca:\n",
    "        features = pca.transform(features)\n",
    "\n",
    "    prediction = model.predict(features)[0]\n",
    "    confidence = model.decision_function(features)[0]\n",
    "    result = CLASSES[prediction]\n",
    "    print(f\"Tahmin: {result} (güven: {confidence:.4f})\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e7f20",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"HOG+SVM Mask Classification - Eğitim\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model, pca = train_and_evaluate()\n",
    "    \n",
    "    print(\"\\nEğitim tamamlandı!\")\n",
    "    print(f\"Model dosyası: {MODEL_FILE}\")\n",
    "    if pca:\n",
    "        print(f\"PCA dosyası: {PCA_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
